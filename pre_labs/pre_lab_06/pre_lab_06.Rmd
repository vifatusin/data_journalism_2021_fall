---
title: "pre_lab_06.Rmd"
author: "derek willis"
date: "8/24/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Points to hit
1. Review of fifth lab questions/problems.
2. Demonstration of PDF parsing with Tabula

### Task 1: Load libraries
**Task** Run the following code in the gray-colored codeblock below -- not in the console -- to load the tidyverse library. To run the code, click the little green play button (left facing arrow) at the top right of the codeblock. In Rmarkdown data notebooks, we write code inside of codeblocks, and explanatory text in the white area outside of it.

```{r}
# turn off sci notation
options(scipen=999)
library(tidyverse)
```

## PDF Parsing with Tabula

Tabula works best when tables in PDFs are clearly defined and have nicely-formatted information. Here's a perfect example: [active voters by county in Maryland](https://elections.maryland.gov/press_room/2020_stats/Eligible%20Active%20Voters%20by%20County%20-%20PG20.pdf).

### Task 1: Download and Install Tabula

**Task**: [Download and install Tabula](https://tabula.technology/). Tabula works much the same way as Open Refine does -- it works in the browser by spinning up a small webserver in your computer. Start it as you would any other desktop application, then go to http://127.0.0.1:8080/ in your browser.

When Tabula opens, you click browse to find the PDF on your computer somewhere, and then click import. After it imports, click autodetect tables. You'll see red boxes appear around what Tabula believes are the tables. You'll see it does a pretty good job at this.

```{r, echo=FALSE}
knitr::include_graphics(rep("images/md_voters.png"))
```

ow you can hit the green "Preview & Export Extracted Data" button on the top right. You should see something very like this:

```{r, echo=FALSE}
knitr::include_graphics(rep("images/md_voters2.png"))
```

You can now export that extracted table to a CSV file using the "Export" button. And then we can read it into R:

### Task 2: Load data
**Task** Load the Maryland voters by county data by running the following codeblock.

```{r}
voters_by_county <- read_csv("tabula-md_voters.csv")
View(voters_by_county)
```

Boom - we're good to go.

## When it looks good, but needs a little fixing

### Task 3: Parsing another PDF
**Task** Here's a slightly more involved PDF. Check out the table on page 4 of [this SBA PDF](https://www.sba.gov/sites/default/files/2021-06/PPP_Report_Public_210531-508.pdf).

```{r, echo=FALSE}
knitr::include_graphics(rep("images/ppp_1.png"))
```

Looks like a spreadsheet, right? Save that PDF file to your computer in a place where you'll remember it (like a Downloads folder).

Now let's repeat the steps we did to import the PDF into Tabula and autodetect the tables. Page 4 should look like this:

```{r, echo=FALSE}
knitr::include_graphics(rep("images/ppp_2.png"))
```

We just want the table on page 4, which shows 2021 loan activity by type of lender, so hit the "Clear All Selections" button to remove the red boxes. Now, in Tabula, let's draw a box around the table on page 4. Click and drag to draw the box.

Now you can hit the green "Preview & Export Extracted Data" button on the top right. You should see something very like this:

```{r, echo=FALSE}
knitr::include_graphics(rep("images/ppp_3.png"))
```

You can now export that extracted table to a CSV file using the "Export" button. And then we can read it into R:

### Task 4: Loading data
**Task** Run the following code to load the CSV file into R.

```{r}
lender_types <- read_csv("tabula-ppp_report.csv")
View(lender_types)
```

### Task 5: Cleaning up the data in R
**Task** Run the following code to load and clean up the data

```{r}
lender_types <- read_csv("tabula-ppp_report.csv", skip=1, col_names=c("type", "count", "approved", "net_dollars"))
lender_types <- lender_types %>% mutate(net_dollars=as.numeric(parse_number(net_dollars)))
View(lender_types)
```
